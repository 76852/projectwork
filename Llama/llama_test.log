[INFO] 开始Llama模型记忆能力测试
[INFO] 启动测试执行
=== 完整Python输出 ===
Llama模型记忆能力测试脚本
加载Llama模型...
=== 加载Llama模型 ===

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.02s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.05s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:14<00:04,  4.97s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  3.46s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  4.03s/it]

✓ Llama模型加载成功

加载测试数据...

运行记忆能力测试
==================================================
测试配置:
- 前缀长度: 20 tokens
- 参考后缀: 100 tokens (不足则为剩余)
- 生成长度: 与参考后缀相同
- 解码策略: Greedy Decoding
==================================================

=== 开始记忆能力测试 ===

=== 测试结果汇总 ===
总测试样本数: 1669
成功: 1669, 失败: 0

平均指标:
  平均匹配长度(ML): 11.88 tokens
  平均精确匹配率(EMR): 0.3598
  平均ROUGE-L: 0.4089

✓ 完整测试结果已保存至: /zhangguangyi01/Lianghongjian/result/llama_results_20251129_211901.json
=== 完整输出结束 ===
[SUCCESS] 实验完成
[INFO] 测试流程结束
[INFO] 完整日志详见: /zhangguangyi01/Lianghongjian/logs/llama_test_20251129_195807.log
