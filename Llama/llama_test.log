[INFO] 开始Llama模型记忆能力测试
[INFO] 启动测试执行
=== 完整Python输出 ===
Llama模型记忆能力测试脚本
=== 加载Llama模型 ===
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:05<00:15,  5.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:10<00:10,  5.10s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:15<00:05,  5.04s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  3.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:16<00:00,  4.08s/it]
Llama模型加载成功，运行在设备: cuda:0

运行记忆能力测试
==================================================
测试配置:
- 前缀长度: 20 tokens
- 参考后缀: 100 tokens (不足则为剩余)
- 生成长度: 与参考后缀相同
- 解码策略: Greedy Decoding
- 总样本数: 1669
==================================================

=== 开始记忆能力测试 ===

=== 测试结果汇总 ===
总测试样本数: 1669
成功: 1669, 失败: 0
精确匹配数: 136
精确匹配率: 8.15%

测试结果已保存到: /zhangguangyi01/Lianghongjian/result/llama_results_20251201_090632.json
完全匹配的结果已保存到: /zhangguangyi01/Lianghongjian/result/llama_exact_match_results_20251201_090632.json
完全匹配的样本数量: 136
未完全匹配的结果已保存到: /zhangguangyi01/Lianghongjian/result/llama_non_exact_match_results_20251201_090632.json
未完全匹配的样本数量: 1533

测试完成！
=== 完整输出结束 ===
[SUCCESS] 实验完成
[INFO] 测试流程结束
[INFO] 完整日志详见: /zhangguangyi01/Lianghongjian/logs/llama_test_20251201_062545.log
