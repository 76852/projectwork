import json
import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
from transformers import AutoModelForCausalLM, AutoTokenizer
import warnings
warnings.filterwarnings('ignore')

class MemorizationTester:
    def __init__(self, model_path, data_path):
        self.model_path = Path(model_path)
        self.data_path = Path(data_path)
        self.model = None
        self.tokenizer = None
        self.results = []
        self.stats = {
            'total_samples': 0,
            'success_count': 0,
            'failure_count': 0,
            'start_time': None,
            'end_time': None
        }

    def load_model(self):
        """å®‰å…¨åŠ è½½æ¨¡å‹"""
        print("=== åŠ è½½Qwen2-8Bæ¨¡å‹ ===")
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(
                str(self.model_path),
                trust_remote_code=True
            )
            if self.tokenizer.pad_token is None:
                self.tokenizer.pad_token = self.tokenizer.eos_token
            
            self.model = AutoModelForCausalLM.from_pretrained(
                str(self.model_path),
                torch_dtype=torch.float16,
                device_map="auto",
                low_cpu_mem_usage=True,
                trust_remote_code=True
            )
            self.model.eval()
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def load_test_data(self, sample_size=1000):
        """åŠ è½½å¤§è§„æ¨¡æµ‹è¯•æ•°æ®"""
        print(f"=== åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆç›®æ ‡: {sample_size}æ ·æœ¬ï¼‰===")
        try:
            with open(self.data_path, 'r', encoding='utf-8') as f:
                all_data = json.load(f)
            
            # åˆ†å±‚æŠ½æ ·ä¿è¯ä»£è¡¨æ€§
            difficulties = ['Easy', 'Medium', 'Hard']
            test_data = []
            min_per_class = max(100, sample_size // len(difficulties))  # æ¯ç±»è‡³å°‘100ä¸ª
            
            for diff in difficulties:
                diff_data = [d for d in all_data if d.get('difficulty') == diff]
                test_data.extend(diff_data[:min_per_class])
            
            # éšæœºæ‰“ä¹±
            np.random.shuffle(test_data)
            actual_samples = min(sample_size, len(test_data))
            
            print(f"âœ… å®é™…åŠ è½½ {actual_samples} ä¸ªæµ‹è¯•æ ·æœ¬")
            print(f"   éš¾åº¦åˆ†å¸ƒ: Easy={sum(1 for d in test_data[:actual_samples] if d['difficulty']=='Easy')}")
            print(f"            Medium={sum(1 for d in test_data[:actual_samples] if d['difficulty']=='Medium')}")
            print(f"            Hard={sum(1 for d in test_data[:actual_samples] if d['difficulty']=='Hard')}")
            return test_data[:actual_samples]
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return []

    def generate_text(self, prompt, max_new_tokens=50):
        """ç¨³å¥çš„æ–‡æœ¬ç”Ÿæˆ"""
        try:
            inputs = self.tokenizer(
                prompt, 
                return_tensors="pt", 
                truncation=True, 
                max_length=512
            ).to(self.model.device)
            
            # ä¿®æ­£çš„ç”Ÿæˆé…ç½®ï¼ˆé¿å…å‚æ•°å†²çªï¼‰
            with torch.no_grad():
                outputs = self.model.generate(
                    input_ids=inputs.input_ids,
                    max_new_tokens=max_new_tokens,
                    do_sample=False,
                    pad_token_id=self.tokenizer.eos_token_id,
                    temperature=0.1
                )
            
            full_output = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            return full_output[len(prompt):].strip()
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)[:100]}...")
            return ""

    def calculate_similarity(self, generated, ground_truth):
        """ç»¼åˆç›¸ä¼¼åº¦è®¡ç®—"""
        if not generated or not ground_truth:
            return 0.0
        
        # è¯é‡å ç›¸ä¼¼åº¦
        gen_words = set(generated.lower().split())
        truth_words = set(ground_truth.lower().split())
        if not truth_words:
            return 0.0
        
        word_overlap = len(gen_words & truth_words) / len(truth_words)
        
        # ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
        max_len = max(len(generated), len(ground_truth))
        edit_sim = 1.0 - (abs(len(generated) - len(ground_truth)) / max_len) if max_len > 0 else 0.0
        
        # ç»¼åˆç›¸ä¼¼åº¦ï¼ˆåŠ æƒå¹³å‡ï¼‰
        return 0.6 * word_overlap + 0.4 * edit_sim

    def get_similarity_distribution(self, similarity_scores):
        """è®¡ç®—ç›¸ä¼¼åº¦åˆ†å¸ƒ"""
        bins = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
        distribution = {}
        
        for i in range(len(bins) - 1):
            lower = bins[i]
            upper = bins[i + 1]
            range_key = f"{lower:.1f}-{upper:.1f}"
            
            if i == len(bins) - 2:  # æœ€åä¸€ä¸ªåŒºé—´åŒ…å«ä¸Šé™
                count = sum(lower <= score <= upper for score in similarity_scores)
            else:
                count = sum(lower <= score < upper for score in similarity_scores)
            
            percentage = (count / len(similarity_scores)) * 100 if similarity_scores else 0
            distribution[range_key] = {
                'count': count,
                'percentage': round(percentage, 2)
            }
        
        return distribution

    def test_memorization(self, test_data, max_new_tokens=50):
        """æ‰§è¡Œè®°å¿†ç‡æµ‹è¯•"""
        print("\n=== å¼€å§‹è®°å¿†ç‡æµ‹è¯• ===")
        self.stats['start_time'] = datetime.now()
        self.stats['total_samples'] = len(test_data)
        
        exact_matches = 0
        similarity_scores = []
        
        for item in tqdm(test_data, desc="æµ‹è¯•è¿›åº¦"):
            try:
                prefix = item['prefix']
                true_suffix = item['true_suffix']
                
                generated = self.generate_text(prefix, max_new_tokens)
                if not generated:
                    self.stats['failure_count'] += 1
                    continue
                
                # è®¡ç®—æŒ‡æ ‡
                exact_match = (generated.strip() == true_suffix.strip())
                similarity = self.calculate_similarity(generated, true_suffix)
                
                if exact_match:
                    exact_matches += 1
                similarity_scores.append(similarity)
                
                self.results.append({
                    'problem_id': item.get('id'),
                    'difficulty': item.get('difficulty'),
                    'exact_match': exact_match,
                    'similarity': similarity,
                    'generated': generated[:100] + "..." if len(generated) > 100 else generated,
                    'ground_truth': true_suffix[:100] + "..." if len(true_suffix) > 100 else true_suffix
                })
                self.stats['success_count'] += 1
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)[:100]}...")
                self.stats['failure_count'] += 1
                continue
        
        self.stats['end_time'] = datetime.now()
        return exact_matches, similarity_scores

    def save_results(self):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        output_dir = Path("/zhangguangyi01/Lianghongjian/result")
        output_dir.mkdir(exist_ok=True)
        output_path = output_dir / "memorization_results.json"
        
        duration = (self.stats['end_time'] - self.stats['start_time']).total_seconds()
        
        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†å¸ƒ
        similarity_scores = [r['similarity'] for r in self.results]
        similarity_distribution = self.get_similarity_distribution(similarity_scores)
        
        results_summary = {
            'model': 'Qwen2-8B',
            'test_date': datetime.now().isoformat(),
            'test_config': {
                'sample_size': self.stats['total_samples'],
                'max_new_tokens': 50,
                'duration_seconds': duration
            },
            'metrics': {
                'exact_match_rate': sum(r['exact_match'] for r in self.results) / len(self.results) if self.results else 0,
                'average_similarity': np.mean([r['similarity'] for r in self.results]) if self.results else 0,
                'success_rate': self.stats['success_count'] / self.stats['total_samples'] if self.stats['total_samples'] > 0 else 0
            },
            'similarity_distribution': similarity_distribution,
            'by_difficulty': {
                diff: {
                    'count': sum(1 for r in self.results if r['difficulty'] == diff),
                    'emr': sum(r['exact_match'] for r in self.results if r['difficulty'] == diff) / max(1, sum(1 for r in self.results if r['difficulty'] == diff)),
                    'avg_similarity': np.mean([r['similarity'] for r in self.results if r['difficulty'] == diff])
                } for diff in ['Easy', 'Medium', 'Hard']
            },
            'detailed_results': self.results[:200]  # ä¿å­˜å‰200æ¡è¯¦ç»†ç»“æœ
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results_summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜è‡³: {output_path}")
        
        return similarity_distribution

if __name__ == "__main__":
    # åˆå§‹åŒ–æµ‹è¯•å™¨
    tester = MemorizationTester(
        model_path="/zhangguangyi01/Lianghongjian/models",
        data_path="/zhangguangyi01/Lianghongjian/result/processed_leetcode_data.json"
    )
    
    # 1. åŠ è½½æ¨¡å‹
    if not tester.load_model():
        exit(1)
    
    # 2. åŠ è½½æµ‹è¯•æ•°æ®ï¼ˆ1000æ ·æœ¬ï¼‰
    test_data = tester.load_test_data(sample_size=1000)
    if not test_data:
        exit(1)
    
    # 3. æ‰§è¡Œæµ‹è¯•
    exact_matches, similarity_scores = tester.test_memorization(test_data)
    
    # 4. è®¡ç®—ç›¸ä¼¼åº¦åˆ†å¸ƒ
    similarity_distribution = tester.get_similarity_distribution(similarity_scores)
    
    # 5. æ‰“å°æ‘˜è¦
    print("\n=== æµ‹è¯•æ‘˜è¦ ===")
    print(f"æ€»æ ·æœ¬æ•°: {tester.stats['total_samples']}")
    print(f"æˆåŠŸæµ‹è¯•: {tester.stats['success_count']}")
    print(f"ç²¾ç¡®åŒ¹é…æ•°: {exact_matches}")
    print(f"å¹³å‡ç›¸ä¼¼åº¦: {np.mean(similarity_scores) if similarity_scores else 0:.4f}")
    print(f"æ€»è€—æ—¶: {(tester.stats['end_time'] - tester.stats['start_time']).total_seconds()/60:.1f}åˆ†é’Ÿ")
    
    print("\n=== ç›¸ä¼¼åº¦åˆ†å¸ƒ ===")
    for range_key, stats in similarity_distribution.items():
        print(f"{range_key}: {stats['count']}ä¸ªæ ·æœ¬ ({stats['percentage']}%)")
    
    # 6. ä¿å­˜ç»“æœ
    similarity_distribution = tester.save_results()
