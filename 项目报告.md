# 项目实践——面向机器学习的数据清洗方法

## 一、报告内容

### 1. 项目背景与意义
在当今的机器学习领域，数据质量对模型性能和可靠性具有至关重要的影响。然而，现实世界中的数据集常存在各类质量问题，其中标签噪声是最常见且最具挑战性的问题之一。标签噪声指数据集中的错误标注或误导性标注，可能对模型训练和预测产生负面影响。

研究表明，即使小比例的标签噪声也可能导致模型性能显著下降；极端情况下，甚至会使模型学习到错误模式，产生误导性预测结果。这不仅影响模型准确性，还降低其实际应用中的可靠性。

为解决标签噪声问题，研究人员提出多种基于置信学习的方法。置信学习是专门处理标签噪声的机器学习方法，通过估计噪声标签与真实标签的联合分布，识别并校正错误标注样本。其核心利用模型预测概率定位错误标签，优势在于无需超参数调整、能快速识别错误样本，广泛应用于图像分类、语音识别等场景。

### 2. 需求分析
在实际应用中，标签噪声会导致机器学习模型泛化能力下降，影响性能；同时，噪声数据训练会浪费计算资源和时间。因此，开发高效标签清洗方法具有显著实践意义——通过精准识别并校正错误标签，可提升模型训练效率与效果，增强机器学习系统的可靠性。

### 3. 项目内容
- 学习机器学习基础知识
- 通过阅读论文掌握面向机器学习的清洗方法
- 实现数据主动清洗功能

## 二、项目相关概念与技术

### 1. 数据清洗基础
数据清洗是重要的数据预处理步骤，通过一系列技术对原始数据进行整理，确保其符合机器学习算法要求。主要任务包括：剔除无关/重复/噪声数据，处理缺失值与异常值，核心目标是提高数据质量，保障后续分析与模型训练的准确性。

#### 1.1 缺失值处理
数据集中的缺失值可能导致模型训练不稳定或预测不准。常见处理方法：
- 删除含缺失值的记录（适用于缺失比例较低时）
- 填充缺失值（如均值、中位数、众数填充，或基于模型的预测填充）

#### 1.2 异常值处理
异常值（偏离正常范围的数据点）可能干扰模型训练与预测，导致拟合过度或不足。处理方法包括：
- 基于统计方法（如Z-score、IQR）识别并剔除
- 对异常值进行修正（如截断至合理范围）

### 2. 置信学习核心概念
#### 2.1 置信学习方法
置信学习是针对标签噪声的机器学习方法，通过估计噪声标签（\( 	ilde{y} \)）与真实标签（\( y^* \)）的联合分布，识别并校正错误标注样本。核心思想是利用模型预测概率定位错误标签，提升模型准确性与鲁棒性。

#### 2.2 噪声联合分布
噪声联合分布指观测标签与真实标签的联合概率分布，用于量化分析标签噪声的统计特性。通过分析该分布，可深入理解数据集中的噪声模式，指导清洗策略制定。

#### 2.3 主动标签清理
主动标签清理是基于模型置信度的标注优化方法，通过模型预测概率或确定性评估，优先标注高价值样本（模型最不确定的样本）。该方法可提升数据标注效率与质量，进而优化模型性能。

## 三、项目系统与功能设计

### 1. 系统模块设计
项目系统包含三大核心模块：

| 模块名称         | 核心功能                                                                 |
|------------------|--------------------------------------------------------------------------|
| 数据预处理模块   | 加载原始数据集，执行缺失值填充、异常值剔除等基础清洗操作，输出规范数据集 |
| 标签清洗模块     | 基于置信学习方法识别并清洗噪声标签，提升数据集标签质量                   |
| 模型训练模块     | 使用清洗后数据训练监督学习模型（如分类模型），完成评估与超参调优         |

### 2. 核心功能设计
系统提供以下关键功能：
- **标签噪声检测与清洗**：识别并清除数据集中的错误标签，提高数据质量
- **噪声联合分布估计**：量化分析标签噪声的统计特性，辅助清洗策略制定
- **数据清洗与模型训练集成**：支持从数据导入到模型输出的全流程自动化处理

用户可通过以下流程使用系统：
1. 导入数据集（支持CSV/JSON等常见格式）
2. 配置清洗参数（噪声识别阈值、清洗预算）
3. 启动训练流程，系统自动完成预处理、清洗与模型训练
4. 评估模型性能，对比不同清洗方法效果

## 四、项目关键技术与实现

### 1. 数据预处理技术
#### 1.1 数据清理
数据清理是预处理首要任务，目标是修正或删除不正确/干扰数据。主要步骤：
1. **去重与筛选**：删除重复记录，剔除无关数据
2. **结构修复**：统一数据格式（如日期、数值范围）
3. **缺失值处理**：填充/删除/插值处理缺失数据
4. **数据验证**：通过一致性检查、范围检查等确保数据准确性

#### 1.2 噪声处理
噪声处理用于减少随机误差与异常值的影响。常用方法：
- **分箱（Binning）**：将连续数据分组到离散区间，降低微小误差影响
- **回归（Regression）**：通过变量关系建模，削弱噪声干扰
- **聚类（Clustering）**：通过数据分组识别并处理噪声点

#### 1.3 数据集成
数据集成整合多源数据，支持两种模式：
- **紧耦合**：合并多数据源为单一数据库（需解决格式/类型冲突）
- **松耦合**：通过数据仓库/湖仓一体查询（保持数据源独立）

#### 1.4 数据转换
为统一特征尺度，需进行归一化处理。常见方法：
- 最小-最大标准化：将数据缩放到[0,1]区间
- Z分数标准化：转换为标准正态分布（均值0，标准差1）
- 十进制缩放：通过除以10的幂次缩小数据尺度

### 2. 先进数据清洗技术
#### 2.1 HoloClean
HoloClean专注于结构化数据集，目标是识别和修复所有单元格数据，任务分为识别错误的单元格和推断检测到的错误单元的真实值。
HoloClean基于概率推理的整体数据修复框架，结合完整性约束、外部字典验证与统计属性，自动生成修复程序。相较于传统方法，F1平均值提升超2倍。

#### 2.2 CleanML
用于评估数据清理技术对模型性能影响的框架。在CleanML中训练试验新模型/算法，并将其性能与其他模型比较。研究表明：数据清理未必改善模型效果，但选择合适模型可消除其负面影响。

#### 2.3 ActiveClean
支持渐进式数据清理的框架，通过迭代清洗脏数据并更新模型，保证收敛性。适用于线性回归、SVM等凸损失模型。

#### 2.4 TARS系统
通过预测标签清洁后的模型改进程度，判断标签是否值得检查。核心步骤：识别低置信度标签→估计清洁后模型准确性→对比当前模型决定是否清洗。

### 3. 基于置信学习的清洗方法

#### 3.1 计算概率阈值
第一步通过样本的预测概率计算类别相关的概率阈值：
$$ t_{j} = \frac{1}{\left|\boldsymbol{X}_{\tilde{y}=j}\right|} \sum_{\boldsymbol{x}\in\boldsymbol{X}_{\tilde{y}=j}} \hat{p}(\tilde{y}=j;\boldsymbol{x},\boldsymbol{\theta}) $$

#### 3.2 构建置信度联合计数矩阵
通过以下两个条件判断样本的真实标签：
1. 该标签的预测概率在所有标签概率中最大；
2. 该标签的预测概率大于第一步计算的对应阈值。

基于上述条件，构建置信度联合计数矩阵 $\boldsymbol{C}$（行表示预测标签，列表示真实标签），其中 $C[i][j]$ 表示真实标签为 $j$ 且预测标签为 $i$ 的样本数量：
$$ \boldsymbol{C}_{\tilde{y}, y^{*}}[i][j] := \left|\hat{\boldsymbol{X}}_{\tilde{y}=i, y^{*}=j}\right| $$

其中，满足条件的样本集合定义为：
$$ \hat{\boldsymbol{X}}_{\tilde{y}=i, y^{*}=j} := \left\{ \boldsymbol{x}\in\boldsymbol{X}_{\tilde{y}=i} : \begin{aligned} &\hat{p}(\tilde{y}=j;\boldsymbol{x},\boldsymbol{\theta}) \geq t_{j}, \\ &j = \underset{l\in[m]:\hat{p}(\tilde{y}=l;\boldsymbol{x},\boldsymbol{\theta}) \geq t_{l}}{\arg\max} \hat{p}(\tilde{y}=l;\boldsymbol{x},\boldsymbol{\theta}) \end{aligned} \right\} $$

#### 3.3 校准数据分布
由于概率阈值限制，部分样本未被计入置信度联合计数矩阵（矩阵样本数 $\leq$ 真实样本数），需对矩阵进行校准：
$$ \tilde{C}_{\tilde{y}=i, y^{*}=j} \leftarrow \frac{C_{\tilde{y}=i, y^{*}=j}}{\sum_{j\in[m]} C_{\tilde{y}=i, y^{*}=j}} \cdot \left|\boldsymbol{X}_{\tilde{y}=i}\right| $$

#### 3.4 计算置信度联合概率分布矩阵
最终通过校准后的计数矩阵计算联合概率分布：
$$ \hat{Q}_{\tilde{y}=i, y^{*}=j} = \frac{ \frac{C_{\tilde{y}=i, y^{*}=j}}{\sum_{j\in[m]}C_{\tilde{y}=i,y^{*}=j}} \cdot \left|\boldsymbol{X}_{\tilde{y}=i}\right| }{ \sum_{i,j\in[m]} \left( \frac{C_{\tilde{y}=i,y^{*}=j}}{\sum_{j^{\prime}\in[m]}C_{\tilde{y}=i,y^{*}=j^{\prime}}} \cdot \left|\boldsymbol{X}_{\tilde{y}=i}\right| \right) } $$

## 五、项目部署与测试

## 六、参考文献
- Maharana K, Mondal S, Nemade B. A review: Data pre-processing and data augmentation techniques[J]. 2022.
- Regular Paper. Data collection and quality challenges in deep learning: a data-centric AI perspective[J]. 2023.
- HoloClean: Holistic Data Repairs with Probabilistic Inference[J].
- a benchmark for joint data cleaning and machine learning[J].
- ActiveClean: interactive data cleaning for statistical modeling[J].
- Active label cleaning for improved dataset quality under resource constraints[J].
- Northcutt C, Jiang L, Chuang I. Confident Learning: Estimating Uncertainty in Dataset Labels[J].

## 七、总结与感悟

这学期，我每周都会投入一定时间在数据清洗的项目实践中，包括阅读论文、了解和使用基础工具等。这些经历让我深刻认识到，想要掌握真正有意义且实用的知识，并非纸上谈兵那么简单，而是需要亲自实践、思考、探索、总结和成长。而且，这些知识和技能在未来工作中极有可能派上用场，但大学里通常不会有老师专门教授，这就需要我们主动去了解并深入学习。

在我看来，数据清洗的难点在于数据的多样性，不同类型的数据需要采用不同的清洗方法。此外，数据量可能非常庞大，导致数据清洗的时间成本很高。对于简单的项目，数据清洗可能只需十几行代码就能完成。然而，在科研领域，则需要更先进、高效的技术，远非十几行代码所能解决。

我也深刻理解了数据清洗的重要性。如果数据未经清洗直接用于模型训练，模型的效果可能会大打折扣。例如，一个模型的准确率原本为90%，但如果数据没有经过清洗，其准确率可能会降至80%。这是因为数据中的噪声、异常值和缺失值等因素会对模型的训练产生负面影响。数据清洗的目的正是为了确保模型在训练过程中能够更好地学习数据的特征，从而提升模型的准确率。



